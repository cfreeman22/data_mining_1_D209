{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOXGps+bm/uEcO66iv722KU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cfreeman22/data_mining_1_D209/blob/main/D209_data_mining1_task2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VABiSY9_CPL5"
      },
      "outputs": [],
      "source": [
        "# Libraries to help with reading and manipulating data\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Libraries to help with data visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "#inporting GridSearch and Pipeline from theesklearn library\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "\n",
        "# library to scaling the data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# Library to split data\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# importing the kneighbors classifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "#importing metric to test our model\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    f1_score,\n",
        "    accuracy_score,\n",
        "    recall_score,\n",
        "    precision_score,\n",
        "    confusion_matrix,\n",
        "    roc_auc_score,\n",
        "    plot_confusion_matrix,\n",
        "    precision_recall_curve,\n",
        "    roc_curve, classification_report, \n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Customs funtions\n",
        "# defining a function to compute different metrics to check performance of a classification model built using sklearn\n",
        "\n",
        "def model_performance_classification_sklearn_with_threshold(model, predictors, target, threshold=0.5):\n",
        "    \"\"\"\n",
        "    Function to compute different metrics, based on the threshold specified, to check classification model performance\n",
        "\n",
        "    model: classifier\n",
        "    predictors: independent variables\n",
        "    target: dependent variable\n",
        "    threshold: threshold for classifying the observation as class 1\n",
        "    \"\"\"\n",
        "\n",
        "    # predicting using the independent variables\n",
        "    pred_prob = model.predict_proba(predictors)[:, 1]\n",
        "    pred_thres = pred_prob > threshold\n",
        "    pred = np.round(pred_thres)\n",
        "\n",
        "    acc = accuracy_score(target, pred)  # to compute Accuracy\n",
        "    recall = recall_score(target, pred)  # to compute Recall\n",
        "    precision = precision_score(target, pred)  # to compute Precision\n",
        "    f1 = f1_score(target, pred)  # to compute F1-score\n",
        "\n",
        "    # creating a dataframe of metrics\n",
        "    df_perf = pd.DataFrame(\n",
        "        {\n",
        "            \"Accuracy\": acc,\n",
        "            \"Recall\": recall,\n",
        "            \"Precision\": precision,\n",
        "            \"F1\": f1,\n",
        "        },\n",
        "        index=[0],\n",
        "    )\n",
        "\n",
        "    return df_perf"
      ],
      "metadata": {
        "id": "I9KSzuflCaIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defining a function to plot the confusion_matrix of a classification model built using sklearn\n",
        "def confusion_matrix_sklearn_with_threshold(model, predictors, target, threshold=0.5):\n",
        "    \"\"\"\n",
        "    To plot the confusion_matrix, based on the threshold specified, with percentages\n",
        "\n",
        "    model: classifier\n",
        "    predictors: independent variables\n",
        "    target: dependent variable\n",
        "    threshold: threshold for classifying the observation as class 1\n",
        "    \"\"\"\n",
        "    pred_prob = model.predict_proba(predictors)[:, 1]\n",
        "    pred_thres = pred_prob > threshold\n",
        "    y_pred = np.round(pred_thres)\n",
        "\n",
        "    cm = confusion_matrix(target, y_pred)\n",
        "    labels = np.asarray(\n",
        "        [\n",
        "            [\"{0:0.0f}\".format(item) + \"\\n{0:.2%}\".format(item / cm.flatten().sum())]\n",
        "            for item in cm.flatten()\n",
        "        ]\n",
        "    ).reshape(2, 2)\n",
        "\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.heatmap(cm, annot=labels, fmt=\"\")\n",
        "    plt.ylabel(\"True label\")\n",
        "    plt.xlabel(\"Predicted label\")"
      ],
      "metadata": {
        "id": "S_u68p0tCd7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#reading the data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "8AvyjjSDCihX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Reading the data from my google drive.\n",
        "df = pd.read_csv('/content/drive/My Drive/churn_clean.csv')"
      ],
      "metadata": {
        "id": "VQ7DiDAgCnfW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation steps"
      ],
      "metadata": {
        "id": "cNII1BQkCyol"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#target variable\n",
        "df.Churn.value_counts()\n",
        "\n",
        "df.Churn = df.Churn.map({'Yes':1 ,'No':0}).astype('int')\n",
        "  \n"
      ],
      "metadata": {
        "id": "IUrbNgNmDY9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking for duplicates\n",
        "df.duplicated().sum()"
      ],
      "metadata": {
        "id": "vkuTOosfHAM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking for null\n",
        "df.isnull().values.any()"
      ],
      "metadata": {
        "id": "d5I1Mi-LHF4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping unnecessary columns\n",
        "cols_to_drop =['CaseOrder', 'Customer_id', 'Interaction', 'UID', 'Zip', 'Lat', 'Lng', 'TimeZone','City', 'State', 'County','Job','Population' ]\n",
        "\n",
        "# Dropping unnecessary columns\n",
        "df = df.drop(cols_to_drop, axis = 1)\n",
        "\n",
        "# renaming the survey items columns\n",
        "df = df.rename(columns={'Item1': 'TimelyResponse','Item2': 'TimelyFixes' , 'Item3': 'TimelyReplacements', 'Item4': 'Reliability',\n",
        "\n",
        "                          'Item5': 'Options', 'Item6': 'RespectfulResponse', 'Item7': 'CourteousExchange', 'Item8': 'ActiveListening'})\n",
        "\n",
        "# Checking to confirm if unnecessary columns were dropped and survey columns renamed appropriately\n",
        "\n",
        "df.info()"
      ],
      "metadata": {
        "id": "01Yvd4fGHLBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#extracting categorical variables\n",
        "cat_vars =  df.select_dtypes(include=['object']).columns.to_list()\n",
        "cat_vars"
      ],
      "metadata": {
        "id": "guEU8qx1HT30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting numerical variables\n",
        "for x in df.columns.to_list():\n",
        "  if x not in cat_vars:\n",
        "    print(x)"
      ],
      "metadata": {
        "id": "KtsFc0TEHVey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Changing object type to categories\n",
        "for col in cat_vars:\n",
        "   df[col] = df[col].astype('category')"
      ],
      "metadata": {
        "id": "BLk-PXepHdUn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Renaming some categories for easy processing\n",
        "df.Marital = df.Marital.cat.rename_categories({\"Divorced\":\"Divorced\",\"Widowed\": \"Widowed\",\"Separated\": \"Separated\", \"Never Married\": \"NeverMarried\", \"Married\":\"Married\"}) \n",
        "df.Contract = df.Contract.cat.rename_categories({\"Month-to-month\":\"month_to_month\",\"Two Year\": \"TwoYear\",\"One year\": \"OneYear\"})\n",
        "df.InternetService = df.InternetService.cat.rename_categories({\"Fiber Optic\":\"Fiber\",\"DSL\": \"DSL\",\"None\": \"NoService\"})\n",
        "df.PaymentMethod = df.PaymentMethod.cat.rename_categories({\"Electronic Check\":\"ElectronicCheck\",\"Mailed Check\": \"MailedCheck\",\"Bank Transfer(automatic)\": \"BankTransfer\",\n",
        "                                                           \"Credit Card (automatic)\": \"CreditCard\"}) "
      ],
      "metadata": {
        "id": "0F-gIOSGHnDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## DROP EITHER TENURE OR BANDWIDTH from previous analysis these two features were highly correlated\n",
        "df = df.drop('Bandwidth_GB_Year', axis = 1)"
      ],
      "metadata": {
        "id": "K94U49trHvmJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving the cleaned data set"
      ],
      "metadata": {
        "id": "7FuGJP7fHz-n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#making a copy of the prepared dataset and extract a copy for submission\n",
        "\n",
        "churn_df =  df.copy()"
      ],
      "metadata": {
        "id": "S9RTl6MKH3CP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cleaned and prepared data\n",
        "#churn_df.to_csv('cleaned_prepared_churn2.csv')"
      ],
      "metadata": {
        "id": "z3RciiiXH9kw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Train Split and Scaling"
      ],
      "metadata": {
        "id": "uxxulchbIFWg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = churn_df\n",
        "y = X.pop('Churn')\n",
        "#Getting dummy variables for categorical columns\n",
        "X = pd.get_dummies(X, drop_first=True)"
      ],
      "metadata": {
        "id": "d6az32avIa60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#spliting the data\n",
        "X_train, X_test, y_train, y_test = train_test_split( X, y, \n",
        "                                                    test_size=0.3, random_state=42, stratify=y)"
      ],
      "metadata": {
        "id": "OEjh8c_qJyeT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training_set = pd.concat([X_train, y_train], axis=1)\n",
        "#test_set = pd.concat([X_test, y_test], axis=1)\n",
        "\n",
        "#training_set.to_csv('training_set2.csv', index=False)\n",
        "#test_set.to_csv('test_set2.csv', index=False)"
      ],
      "metadata": {
        "id": "5213lcqmJ6t-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "oePNiGBkJ5ma"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "s3oz4-rBJwNi"
      }
    }
  ]
}